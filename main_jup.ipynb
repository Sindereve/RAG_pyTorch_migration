{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40530bd",
   "metadata": {},
   "source": [
    "# Тема 'RAG для миграции pyTorch с v1.0.0 на v2.7.0' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c203cc94",
   "metadata": {},
   "source": [
    "## Настройка для использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe282da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 13:25:18,630 | INFO     | __main__ | Модель intfloat/e5-large загружена\n",
      "2025-07-27 13:25:22,191 | INFO     | __main__ | БД подключена\n"
     ]
    }
   ],
   "source": [
    "from logs.logging_setup import configure_logging\n",
    "configure_logging()\n",
    "import logging\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "from validator import Validator\n",
    "from retrival import Retreiver, get_embedding_core\n",
    "from llm import get_llm_response, clean_llm_code\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "LLM_NAME = \"tngtech/deepseek-r1t2-chimera\"\n",
    "\n",
    "# =========  Загрузка модели =================\n",
    "model, tokenizer = get_embedding_core(\"intfloat/e5-large\")\n",
    "LOGGER.info(f\"Модель {model.model_name} загружена\")\n",
    "\n",
    "# =========  Подключение к БД =================\n",
    "rtr = Retreiver(model, model.model_name)\n",
    "LOGGER.info(f\"БД подключена\")\n",
    "\n",
    "# =========  Инициализация валидатора =================\n",
    "val = Validator()\n",
    "\n",
    "def RAG_get_new_code(code, model_name):\n",
    "    '''\n",
    "        Получаем новый код после прогана в RAG\n",
    "    '''\n",
    "    prompt = rtr.build_prompt(code)\n",
    "    LOGGER.info(f\"Запрос в БД успешно выполнен\")\n",
    "\n",
    "    result = get_llm_response(prompt, model_name=model_name)\n",
    "    LOGGER.info(f\"Запрос в LLM успешно выполнен\")\n",
    "\n",
    "    result_code = clean_llm_code(result)\n",
    "    LOGGER.info(f\"Получен код из ответа LLM\")\n",
    "\n",
    "    return result_code\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be239e5d",
   "metadata": {},
   "source": [
    "## **Что такое RAG и почему он нужен бизнесу**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c11caa",
   "metadata": {},
   "source": [
    "![Репозитории в gitHub](data\\image\\more_rag_github.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8201322",
   "metadata": {},
   "source": [
    "RAG (Retrieval Augmented Generation) — это метод работы с большими языковыми моделями, когда пользователь пишет свой вопросы, а мы программно к этому вопросу «подмешиваете» дополнительную информацию из каких‑то внешних источников и подаём все целиком на вход языковой модели. Другими словами мы говорим, то о чём наша модель может не знать или \"забыть\" это учесть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d196f1",
   "metadata": {},
   "source": [
    "**Давайте разберём на примере:**\n",
    "\n",
    "*Пользователь*: Какой должен быть шрифт у кода при написании дипломной работы в ОГУ? \n",
    "\n",
    "LLM это не знает с вероятностью почти в 100% и тут появляется несколько исходов у LLM.\n",
    "1) Сказать честно, что она не знает\n",
    "2) Придумать свой вариант\n",
    "3) Найти из интернета, но не факт, что она обратится к нужному источнику для поиска информации.\n",
    "\n",
    "И тут на помощь приходит RAG, он дополняет вопрос пользователя. И поможет LLM ответить правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2d7ba",
   "metadata": {},
   "source": [
    "![Всё хорошо](data\\image\\all_good.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947532e",
   "metadata": {},
   "source": [
    "## Что он может(на данный момент)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfcd93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"torch._six\"\n",
    "old_code = \"\"\"\n",
    "torch.distributed.init_process_grou\": \"import torch.distributed as dist; dist.init_process_group(backend='gloo', init_method='tcp://127.0.0.1:12345', world_size=1, rank=0); print('OK')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ba09cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 16:39:06,515 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-26 16:39:50,045 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-26 16:39:50,046 | INFO     | __main__ | Получен код из ответа LLM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Old code:\n",
      " \n",
      "torch.distributed.init_process_grou\": \"import torch.distributed as dist; dist.init_process_group(backend='gloo', init_method='tcp://127.0.0.1:12345', world_size=1, rank=0); print('OK')\n",
      "\n",
      "==============================\n",
      "New code:\n",
      " import torch.distributed as dist\n",
      "dist.init_process_group(\n",
      "    backend='gloo',\n",
      "    init_method='tcp://127.0.0.1:12345',\n",
      "    world_size=1,\n",
      "    rank=0\n",
      ")\n",
      "print('OK')\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API</th>\n",
       "      <th>Работает в 1.0.0</th>\n",
       "      <th>Out 1.0.0</th>\n",
       "      <th>Err 1.0.0</th>\n",
       "      <th>Работает в 2.7.0</th>\n",
       "      <th>Out 2.7.0</th>\n",
       "      <th>Err 2.7.0</th>\n",
       "      <th>Работает в 2.7.0 (после RAG)</th>\n",
       "      <th>RAG Out 2.7.0</th>\n",
       "      <th>RAG Err 2.7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>torch._six</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpya1...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpetn...</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "      <td>[W726 16:40:16.000000000 socket.cpp:755] [c10d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             API  Работает в 1.0.0 Out 1.0.0  \\\n",
       "Test  torch._six             False             \n",
       "\n",
       "                                              Err 1.0.0  Работает в 2.7.0  \\\n",
       "Test  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpya1...             False   \n",
       "\n",
       "     Out 2.7.0                                          Err 2.7.0  \\\n",
       "Test            File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpetn...   \n",
       "\n",
       "      Работает в 2.7.0 (после RAG) RAG Out 2.7.0  \\\n",
       "Test                         False            OK   \n",
       "\n",
       "                                          RAG Err 2.7.0  \n",
       "Test  [W726 16:40:16.000000000 socket.cpp:755] [c10d...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_code = RAG_get_new_code(old_code, LLM_NAME)\n",
    "dict_info, dict_code = val.run_test_old_and_new_code(name, old_code, new_code)\n",
    "\n",
    "print('='*30)\n",
    "print('Old code:\\n',dict_code['old_code'])\n",
    "print('='*30)\n",
    "print('New code:\\n',dict_code['new_code'])\n",
    "print('='*30)\n",
    "\n",
    "pd.DataFrame(dict_info, index=['Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca20b61",
   "metadata": {},
   "source": [
    "## Обзор архитектуры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1904dacc",
   "metadata": {},
   "source": [
    "### **Откуда мы брали данные и почему именно эти данные?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a98d8a",
   "metadata": {},
   "source": [
    "Прежде чем приступать к архитектуре, давайте так же затронем не мало важную тему.\n",
    "\n",
    "СБОР ДАННЫХ!!\n",
    "\n",
    "\n",
    "Да, сбор данных это одна из важнейших ступеней в построении хорошей RAG системы. А всё потому что вы можете сделать ЛУЧШУЮ архитектуру, ЛУЧШИЕ методы поиска информации, ЛУЧШАЯ LLM, ЛУЧШИЙ промт, ЛУЧШИЙ UI... Ну ладно UI это конечно лишние.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a9fda",
   "metadata": {},
   "source": [
    "![image.png](data\\image\\git_pyTorch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b66892",
   "metadata": {},
   "source": [
    "Все данные для создания контекста мы взяли из рилизов опубликованных на [gitHub](https://github.com/pytorch/pytorch/releases)\n",
    "\n",
    "\n",
    "Они идеально подходят для нашей задачи, так как в рилизах прописываются изменения api, а так же есть примеры написания кода, а так же прописывается номер версии. \n",
    "\n",
    "Идеи по улучшению: \n",
    "* Можно добавить документацию по каждой из версий. Это даст больший контекст.\n",
    "* Можно добавить данные из stackOverflou, но их нужно размечать(трудозатратно)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f9330",
   "metadata": {},
   "source": [
    "### **Основные компоненты RAG** + (стэк технологий)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48fbf9",
   "metadata": {},
   "source": [
    "Давайте рассмотрим процесс создания RAG целиком, а потом начнём разбирать каждый элемент в отдельности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0f01a",
   "metadata": {},
   "source": [
    "![RAG](data\\image\\rag_scheme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec889bdd",
   "metadata": {},
   "source": [
    "Разберём препроцессинг "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc6b8a",
   "metadata": {},
   "source": [
    "![Pre-processing](data\\image\\rag_scheme_pre_processing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8622e06f",
   "metadata": {},
   "source": [
    "Подготовка данных:\n",
    "\n",
    "**User Documents:** В нашем случае это рилизы из gitHub\n",
    "\n",
    "**Далее, chunking:** Я выбрал RecursiveCharacterTextSplitter из LangChain, потому что он предлагает гибкий и семантически осмысленный подход к разбиению текста.python.langchain.com Этот сплиттер рекурсивно делит текст по иерархии разделителей (например, сначала по абзацам, затем по предложениям, словам или символам)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee601a1",
   "metadata": {},
   "source": [
    "Для embedding я выбрал модель e5-large-v2, которая лидирует в [MTEB leaderboard](https://modal.com/blog/embedding-models-article). \n",
    "\n",
    "Почему именно она? \n",
    "Эта модель компактна, быстрая в inference, и показывает высокую семантическую схожесть - ключ для RAG, где эмбеддинги должны захватывать нюансы языка. Интегрируется напрямую с LangChain. (Это очень важно для нас, так как подключаемся к БД мы с помощью langChain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c9ed6",
   "metadata": {},
   "source": [
    "Наконец, хранение эмбеддингов: \n",
    "Я использую QDrant в комбинации с LangChain, потому что QDrant - это **AI-native vector database**, оптимизированная для семантического поиска. Интеграция с LangChain проста, через QdrantVectorStore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0ec1e",
   "metadata": {},
   "source": [
    "Теперь мы перейдём к ретривалу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c7717",
   "metadata": {},
   "source": [
    "![Retrieval](data\\image\\rag_scheme_retrival.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47feb874",
   "metadata": {},
   "source": [
    "Этот модуль - сердце RAG. Отвечает за поиск релевантной информации на основе пользовательского запроса. По сути, он работает как умный поисковик: принимает текст запроса, преобразует его в вектор с помощью той же embedding-модели, и выполняет семантический поиск в базе данных QDrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6085d",
   "metadata": {},
   "source": [
    "Код ниже взят из документации [pyTorch v1.0.0](https://docs.pytorch.org/docs/1.0.0/notes/extending.html?highlight=staticmethod%20def%20forward%20ctx%20input%20weight%20bias%20none%20ctx%20save_for_backward%20input%20weight%20bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c41197",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_code = \"\"\"\n",
    "import torch\n",
    "from torch.autograd import gradcheck, Function\n",
    "\n",
    "class LinearFunction(Function):\n",
    "\n",
    "    \n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def backward(ctx, grad_output):\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output.mm(weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n",
    "\n",
    "input = (torch.randn(20,20,dtype=torch.double,requires_grad=True), torch.randn(30,20,dtype=torch.double,requires_grad=True))\n",
    "linear = LinearFunction.apply\n",
    "test = gradcheck(linear, input, eps=1e-6, atol=1e-4)\n",
    "print(test)\n",
    "\n",
    "\"\"\"\n",
    "documents = rtr._get_retriever_for_langChain(k=6).invoke(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e927b12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'version': 'v1.2.0', 'release_name': 'New TorchScript API with Improved Python Language Coverage, Expanded ONNX Export, NN.Transformer', 'chunk_id': 'v1.2.0-51', '_id': '3dbcc1bb-db5a-46d9-b2a2-253a4aacd2ea', '_collection_name': 'migTorch_test_intfloat_e5-large'}, page_content=\"is now deprecated, please use 'out' parameter with dtype torch.bool instead.\\r\\n\\r\\ntensor([0, 1, 1], dtype=torch.uint8)\\r\\n\\r\\n# instead use torch.bool\\r\\n>>> res = torch.empty_like(a, dtype=torch.bool)\\r\\n>>> torch.gt(a, b, out=res)\\r\\ntensor([False, True, True])\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n### Legacy `autograd.Function` (Function without static forward method) is now deprecated\\r\\n\\r\\n```\\r\\n>>> class MyLegacyFunction(Function):\\r\\n>>>     def forward(self, x):\\r\\n>>>         return x\\r\\n>>>\\r\\n>>>     def backward(self, grad_output):\\r\\n>>>         return grad_output\\r\\n>>>\\r\\n>>> MyLegacyFunction()(torch.randn((3,), requires_grad=True)\\r\\nUserWarning: Legacy autograd function with non-static forward method is deprecated\\r\\nand will be removed in 1.3. Please use new-style autograd function\\r\\nwith static forward method.\\r\\n\\r\\n# instead use new-style Autograd Function\\r\\n>>> class MyFunction(Function):\\r\\n>>>     @staticmethod\\r\\n>>>     def forward(ctx, x):\\r\\n>>>         return x\\r\\n>>>\\r\\n>>>     @staticmethod\\r\\n>>>     def backward(ctx, grad_output):\\r\\n>>>         return grad_output\\r\\n>>>\\r\\n>>> MyFunction.apply(torch.randn((3,), requires_grad=True)\\r\\n```\\r\\n\\r\\nSee the [torch.autograd.Function](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function) documentation for more details.\\r\\n\\r\\n### `torch.gels`: has been renamed to `torch.lstsq`; `torch.gels` will work for this release but is now deprecated.  ([23460](https://github.com/pytorch/pytorch/pull/23460))\\r\\n\\r\\n## Performance\"),\n",
       " Document(metadata={'version': 'v1.8.0', 'release_name': 'PyTorch 1.8 Release, including Compiler and Distributed Training updates, New Mobile Tutorials and more', 'chunk_id': 'v1.8.0-13', '_id': '1e0afe91-04ca-4227-ab10-3fc0dbf3bec7', '_collection_name': 'migTorch_test_intfloat_e5-large'}, page_content='An example of this discrepancy is shown in the example below where a Linear layer takes as input a single Tensor of size 5 and returns a single Tensor of size 5 but old style hook would return two gradients with respect to the input for only one input.\\r\\n\\r\\n1.7.1:\\r\\n\\r\\n```python\\r\\nimport torch\\r\\nfrom torch import nn\\r\\n\\r\\nmod = nn.Linear(5, 5)\\r\\ndef hook(mod, grad_inp, grad_out):\\r\\n    print(f\"grad input size: \" + \" \".join(str(g.size()) for g in grad_inp))\\r\\n    print(f\"grad output size: \" + \" \".join(str(g.size()) for g in grad_out))\\r\\nmod.register_backward_hook(hook)\\r\\n\\r\\nmod(torch.rand(5, requires_grad=True)).sum().backward()\\r\\n>>> `grad input size: torch.Size([5]) torch.Size([5]) # One too many\\r\\n>>> grad output size: torch.Size([5])`\\r\\n```\\r\\n\\r\\n1.8.0:\\r\\nOld style hooks are deprecated and will warn when providing wrong result.\\r\\n\\r\\n```python\\r\\nimport torch\\r\\nfrom torch import nn\\r\\n\\r\\nmod = nn.Linear(5, 5)\\r\\ndef hook(mod, grad_inp, grad_out):\\r\\n    print(f\"grad input size: \" + \" \".join(str(g.size()) for g in grad_inp))\\r\\n    print(f\"grad output size: \" + \" \".join(str(g.size()) for g in grad_out))\\r\\nmod.register_backward_hook(hook)\\r\\n\\r\\nmod(torch.rand(5, requires_grad=True)).sum().backward()\\r\\n>>> grad input size: torch.Size([5]) torch.Size([5]) # One too many\\r\\n>>> grad output size: torch.Size([5])\\r\\n>>> `UserWarning: Using a non-full backward hook when the forward contains multiple\\r\\nautograd Nodes is deprecated and will be removed in future versions. This hook\\r\\nwill be missing some grad_input.`\\r\\n```'),\n",
       " Document(metadata={'version': 'v1.13.0', 'release_name': 'PyTorch 1.13: beta versions of functorch and improved support for Apple’s new M1 chips are now available', 'chunk_id': 'v1.13.0-6', '_id': 'f45870ba-d440-4f53-a573-ee3c4cca3f23', '_collection_name': 'migTorch_test_intfloat_e5-large'}, page_content='Setting the  `.data` of a tensor that `requires_grad` with an integer tensor now raises an error.\\r\\n\\r\\n1.12.1\\r\\n\\r\\n```python\\r\\n>>> x = torch.randn(2, requires_grad=True)\\r\\n>>> x.data = torch.randint(1, (2,))\\r\\n>>> x\\r\\ntensor([0, 0], requires_grad=True)\\r\\n```\\r\\n\\r\\n1.13\\r\\n\\r\\n```python\\r\\n>>> x = torch.randn(2, requires_grad=True)\\r\\n>>> x.data = torch.randint(1, (2,))\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\nRuntimeError: data set to a tensor that requires gradients must be floating point or complex dtype\\r\\n```\\r\\n\\r\\n### Added variable_list support to ExtractVariables struct (#84583)\\r\\n\\r\\nPrior to this change, C++ custom autograd Function considers tensors passed in TensorList to not be tensors for the purposes of recording the backward graph. After this change, custom Functions that receive TensorList must modify their backward functions to also compute gradients for these additional tensor inputs. Note that this behavior now differs from that of custom autograd Functions in Python.\\r\\n\\r\\n1.12.1\\r\\n\\r\\n```cpp\\r\\nstruct MyFunction : public Function<MyFunction> {\\r\\n    static Variable forward(AutogradContext* ctx, at::Tensor t, at::TensorList tensors) {\\r\\n      return 2 * tensors[0] + 3 * t;\\r\\n    }\\r\\n\\r\\n    static variable_list backward(\\r\\n        AutogradContext* ctx,\\r\\n        variable_list grad_output) {\\r\\n      return {3 * grad_output[0]};\\r\\n    }\\r\\n};\\r\\n```\\r\\n\\r\\n1.13\\r\\n\\r\\n```cpp\\r\\nstruct MyFunction : public Function<MyFunction> {\\r\\n    static Variable forward(AutogradContext* ctx, at::Tensor t, at::TensorList tensors) {\\r\\n      return 2 * tensors[0] + 3 * t;\\r\\n    }\\r\\n\\r\\n    static variable_list backward(\\r\\n        AutogradContext* ctx,\\r\\n        variable_list grad_output) {\\r\\n      return {3 * grad_output[0], 2 * grad_output[0]};\\r\\n    }\\r\\n};\\r\\n```'),\n",
       " Document(metadata={'version': 'v1.7.0', 'release_name': 'PyTorch 1.7 released w/ CUDA 11, New APIs for FFTs, Windows support for Distributed training and more', 'chunk_id': 'v1.7.0-18', '_id': 'e2ff536c-4fa0-4e40-998c-ab56c7f877d9', '_collection_name': 'migTorch_test_intfloat_e5-large'}, page_content='>>> bceloss(a, b)\\r\\nValueError: Using a target size (torch.Size([25, 1]))\\r\\nthat is different to the input size (torch.Size([25]))\\r\\nis deprecated. Please ensure they have the same size.\\r\\n>>> b = b.reshape(25)\\r\\n>>> bceloss(a, b)\\r\\ntensor(1.0604)\\r\\n      </pre></sub></td>\\r\\n    </tr>\\r\\n  </table>\\r\\n</p>\\r\\n\\r\\n### Custom `autograd.Function` stop materializing `None` output Tensors ([#41490](https://github.com/pytorch/pytorch/pull/41490))\\r\\n\\r\\nTo improve performance, the custom `autograd.Function` will not create a Tensor full of zeros when an input is differentiable but the user’s `backward` function returns `None` for it. This means that code for which the `.backward()` or `autograd.grad()` final result will now be `None` while it used to be a Tensor full of zeros.\\r\\nYou can recover the previous behavior by having your custom `autograd.Function` materialize the zero Tensor with `torch.zeros_like(input)` to replace the `None` output for the `backward` method.\\r\\n\\r\\n```python\\r\\nimport torch\\r\\n\\r\\n# Custom Function that returns None for the gradient\\r\\nclass GetTwos(torch.autograd.Function):\\r\\n    @staticmethod\\r\\n    def forward(ctx, inp):\\r\\n        return inp.clone().fill_(2)\\r\\n\\r\\n    @staticmethod\\r\\n    def backward(ctx, grad_out):\\r\\n        # To recover the 1.6 behavior, replace the line below with `return torch.zeros_like(grad_out)`\\r\\n        return None\\r\\n\\r\\na = torch.rand(10, requires_grad=True)\\r\\nb = GetTwos.apply(a)\\r\\nb.sum().backward()\\r\\n\\r\\nprint(a.grad)\\r\\n# In PyTorch 1.6 this will print\\r\\n# tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\\r\\n# In PyTorch 1.7 this will print')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2d33f",
   "metadata": {},
   "source": [
    "Что выдал нам retrival?\n",
    "\n",
    "* v 1.2.0 - говорится, что стоит использовать ```@staticmethod``` перед методами нашей кастомной автоградиентной функцией.\n",
    "\n",
    "* v 1.5.0 - затрагивается ```output = input.mm(weight.t())``` из ```LinearFunction.forward()```  говорится, что лучше клонировать наш вход и работать с клонами. В нашем случае мы именно так и делаем.\n",
    "\n",
    "* v 1.7.0 - изменение поведения градиента ctx.needs_input_grad выводил None, теперь выводит zero.\n",
    "\n",
    "* v 1.13.0 - информация о низкоуровневых изменениях вычисления градиента\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e52ef2",
   "metadata": {},
   "source": [
    "Конеченый этап"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799fc47",
   "metadata": {},
   "source": [
    "![Retrieval](data\\image\\rag_scheme_response.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c3a58",
   "metadata": {},
   "source": [
    "Тут остаётся самое лёгкое, формируется запрос путём подставления изначально запроса и релевантного контекста, о котором нам говорит наш ретривал."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec8fe33",
   "metadata": {},
   "source": [
    "Вот так выглядит наш промт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab07186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_PROMPT_TXT=\"\"\"\n",
    "You are a senior PyTorch engineer helping migrate code from v1.0 to v2.7.\n",
    "\n",
    "### Original code (v1.0)\n",
    "```python\n",
    "{old_code}\n",
    "```\n",
    "\n",
    "### Context (docs & changelog)\n",
    "{context}\n",
    "\n",
    "### Task\n",
    "Rewrite the code so it runs on **PyTorch 2.7**. Explain what you changed.\n",
    "\n",
    "### Answer format\n",
    "```python\n",
    "import torch\n",
    "# updated code here\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f2ea6",
   "metadata": {},
   "source": [
    "## Практика и метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aab0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTS_DICT = {\n",
    "    'torch._six': \"import torch._six; print('OK')\",\n",
    "    'torch.qr': \"import torch; result = torch.qr(torch.tensor([[1.0, 2.0], [3.0, 4.0]])); print('OK')\",\n",
    "    'torch.autograd.function.traceable': \"import torch.autograd.function; print(hasattr(torch.autograd.function.Function, 'traceable'))\",\n",
    "    'torch.testing.make_non_contiguous': \"import torch.testing; t = torch.tensor([1.0]); non_cont = torch.testing.make_non_contiguous(t); print('OK')\",\n",
    "    'torch.gesv': \"import torch; A = torch.tensor([[1.0, 2.0], [3.0, 4.0]]); B = torch.tensor([[5.0], [6.0]]); result = torch.gesv(B, A); print('OK')\",\n",
    "    'torch.potri': \"import torch; A = torch.tensor([[1.0, 0.0], [0.0, 1.0]]); result = torch.potri(A); print('OK')\",\n",
    "    'torch.potrs': \"import torch; B = torch.tensor([[1.0], [2.0]]); U = torch.tensor([[1.0, 2.0], [0.0, 1.0]]); result = torch.potrs(B, U); print('OK')\",\n",
    "    'torch.trtrs': \"import torch; B = torch.tensor([[1.0], [2.0]]); A = torch.tensor([[1.0, 2.0], [0.0, 1.0]]); result = torch.trtrs(B, A); print('OK')\",\n",
    "    'torch.solve': \"import torch; A = torch.tensor([[1.0, 2.0], [3.0, 4.0]]); B = torch.tensor([[5.0], [6.0]]); result = torch.solve(B, A); print('OK')\",\n",
    "    'torch.cholesky_solve': \"import torch; B = torch.tensor([[1.0], [2.0]]); U = torch.tensor([[1.0, 2.0], [0.0, 1.0]]); result = torch.cholesky_solve(B, U); print('OK')\",\n",
    "    'torch.testing.make_tensor (low==high)': \"import torch.testing; t = torch.testing.make_tensor(5, low=1.0, high=1.0, dtype=torch.float32); print('OK')\", \n",
    "    'torch.nn.Module.register_backward_hook': \"import torch.nn as nn; m = nn.Linear(1,1); hook = lambda module, grad_input, grad_output: print('OK'); m.register_backward_hook(hook); print('OK')\", \n",
    "    'torch._export.capture_pre_autograd_graph': \"from torch._export import capture_pre_autograd_graph; import torch; def f(x): return x * 2; captured = capture_pre_autograd_graph(f, (torch.tensor(1.0),)); print('OK')\",\n",
    "    'torch.distributed.init_process_group (old backend)': \"import torch.distributed as dist; dist.init_process_group(backend='gloo', init_method='tcp://127.0.0.1:12345', world_size=1, rank=0); print('OK')\", \n",
    "    'torch.optim.LBFGS (old params)': \"import torch; import torch.optim as optim; params = [torch.tensor([1.0])]; optimizer = optim.LBFGS(params, lr=0.01); print('OK')\",  \n",
    "    'torch.linalg.qr': \"import torch; a = torch.randn(3,3); q, r = torch.linalg.qr(a); print('OK')\",\n",
    "    'torch.linalg.solve': \"import torch; a = torch.randn(3,3); b = torch.randn(3,1); solution = torch.linalg.solve(a, b); print('OK')\",\n",
    "    'torch.linalg.cholesky_inverse': \"import torch; a = torch.randn(3,3); pos_def = a @ a.t() + torch.eye(3); chol = torch.linalg.cholesky(pos_def); inv = torch.linalg.cholesky_inverse(chol); print('OK')\",\n",
    "    'torch.triangular_solve': \"import torch; a = torch.triu(torch.randn(3,3)); b = torch.randn(3,1); solution, cloned_a = torch.triangular_solve(b, a); print('OK')\",\n",
    "    'torch.export.export': \"import torch; def f(x): return x * 2; exported = torch.export.export(f, (torch.tensor(1.0),)); print('OK')\",\n",
    "    'torch.distributed.init_process_group (nccl backend)': \"import torch.distributed as dist; dist.init_process_group(backend='nccl', init_method='tcp://127.0.0.1:12346', world_size=1, rank=0); print('OK')\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8afb436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 18:32:45,064 | INFO     | __main__ | [START TEST] torch._six\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 18:32:52,539 | INFO     | __main__ | torch._six в 1.0.0: Работает\n",
      "2025-07-24 18:33:03,777 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmprkmok7mj.py\", line 1, in <module>\n",
      "    import torch._six; print('OK')\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "ModuleNotFoundError: No module named 'torch._six'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmprkmok7mj.py` failed. (See above for error)\n",
      "2025-07-24 18:33:03,778 | INFO     | __main__ | torch._six в 2.7.0: Не работает\n",
      "2025-07-24 18:33:04,046 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:33:27,598 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:33:27,601 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:33:38,891 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:33:38,893 | INFO     | __main__ | [END TEST] torch._six\n",
      "2025-07-24 18:33:38,894 | INFO     | __main__ | [START TEST] torch.qr\n",
      "2025-07-24 18:33:45,620 | INFO     | __main__ | torch.qr в 1.0.0: Работает\n",
      "2025-07-24 18:33:55,804 | INFO     | __main__ | torch.qr в 2.7.0: Не работает\n",
      "2025-07-24 18:33:56,153 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:34:49,850 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:34:49,851 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:35:00,084 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:35:00,085 | INFO     | __main__ | [END TEST] torch.qr\n",
      "2025-07-24 18:35:00,086 | INFO     | __main__ | [START TEST] torch.autograd.function.traceable\n",
      "2025-07-24 18:35:06,134 | INFO     | __main__ | torch.autograd.function.traceable в 1.0.0: Работает\n",
      "2025-07-24 18:35:16,225 | INFO     | __main__ | torch.autograd.function.traceable в 2.7.0: Работает\n",
      "2025-07-24 18:35:16,491 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:35:44,087 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:35:44,092 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:35:53,972 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:35:53,974 | INFO     | __main__ | [END TEST] torch.autograd.function.traceable\n",
      "2025-07-24 18:35:53,975 | INFO     | __main__ | [START TEST] torch.testing.make_non_contiguous\n",
      "2025-07-24 18:35:59,867 | INFO     | __main__ | torch.testing.make_non_contiguous в 1.0.0: Работает\n",
      "2025-07-24 18:36:09,725 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpw1q8cpme.py\", line 1, in <module>\n",
      "    import torch.testing; t = torch.tensor([1.0]); non_cont = torch.testing.make_non_contiguous(t); print('OK')\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'torch.testing' has no attribute 'make_non_contiguous'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpw1q8cpme.py` failed. (See above for error)\n",
      "2025-07-24 18:36:09,727 | INFO     | __main__ | torch.testing.make_non_contiguous в 2.7.0: Не работает\n",
      "2025-07-24 18:36:09,977 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:37:29,486 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:37:29,489 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:37:40,206 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpdmxarr6x.py\", line 2, in <module>\n",
      "    from torch.testing._internal.common_utils import noncontiguous_like\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\testing\\_internal\\common_utils.py\", line 59, in <module>\n",
      "    import expecttest\n",
      "ModuleNotFoundError: No module named 'expecttest'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpdmxarr6x.py` failed. (See above for error)\n",
      "2025-07-24 18:37:40,209 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Не работает\n",
      "2025-07-24 18:37:40,211 | INFO     | __main__ | [END TEST] torch.testing.make_non_contiguous\n",
      "2025-07-24 18:37:40,212 | INFO     | __main__ | [START TEST] torch.gesv\n",
      "2025-07-24 18:37:46,374 | INFO     | __main__ | torch.gesv в 1.0.0: Работает\n",
      "2025-07-24 18:37:56,594 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpogti1jtk.py\", line 1, in <module>\n",
      "    import torch; A = torch.tensor([[1.0, 2.0], [3.0, 4.0]]); B = torch.tensor([[5.0], [6.0]]); result = torch.gesv(B, A); print('OK')\n",
      "                                                                                                         ^^^^^^^^^^\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\__init__.py\", line 2688, in __getattr__\n",
      "    raise AttributeError(f\"module '{__name__}' has no attribute '{name}'\")\n",
      "AttributeError: module 'torch' has no attribute 'gesv'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpogti1jtk.py` failed. (See above for error)\n",
      "2025-07-24 18:37:56,597 | INFO     | __main__ | torch.gesv в 2.7.0: Не работает\n",
      "2025-07-24 18:37:57,028 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:38:20,130 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:38:20,136 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:38:30,416 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:38:30,417 | INFO     | __main__ | [END TEST] torch.gesv\n",
      "2025-07-24 18:38:30,418 | INFO     | __main__ | [START TEST] torch.potri\n",
      "2025-07-24 18:38:36,610 | INFO     | __main__ | torch.potri в 1.0.0: Работает\n",
      "2025-07-24 18:38:46,955 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmptimv4r_o.py\", line 1, in <module>\n",
      "    import torch; A = torch.tensor([[1.0, 0.0], [0.0, 1.0]]); result = torch.potri(A); print('OK')\n",
      "                                                                       ^^^^^^^^^^^\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\__init__.py\", line 2688, in __getattr__\n",
      "    raise AttributeError(f\"module '{__name__}' has no attribute '{name}'\")\n",
      "AttributeError: module 'torch' has no attribute 'potri'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmptimv4r_o.py` failed. (See above for error)\n",
      "2025-07-24 18:38:46,956 | INFO     | __main__ | torch.potri в 2.7.0: Не работает\n",
      "2025-07-24 18:38:47,298 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:39:55,570 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:39:55,571 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:40:05,789 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:40:05,790 | INFO     | __main__ | [END TEST] torch.potri\n",
      "2025-07-24 18:40:05,791 | INFO     | __main__ | [START TEST] torch.potrs\n",
      "2025-07-24 18:40:12,016 | INFO     | __main__ | torch.potrs в 1.0.0: Работает\n",
      "2025-07-24 18:40:22,280 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpfrcmp0um.py\", line 1, in <module>\n",
      "    import torch; B = torch.tensor([[1.0], [2.0]]); U = torch.tensor([[1.0, 2.0], [0.0, 1.0]]); result = torch.potrs(B, U); print('OK')\n",
      "                                                                                                         ^^^^^^^^^^^\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\__init__.py\", line 2688, in __getattr__\n",
      "    raise AttributeError(f\"module '{__name__}' has no attribute '{name}'\")\n",
      "AttributeError: module 'torch' has no attribute 'potrs'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpfrcmp0um.py` failed. (See above for error)\n",
      "2025-07-24 18:40:22,282 | INFO     | __main__ | torch.potrs в 2.7.0: Не работает\n",
      "2025-07-24 18:40:22,715 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:40:43,007 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:40:43,010 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:40:53,352 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:40:53,354 | INFO     | __main__ | [END TEST] torch.potrs\n",
      "2025-07-24 18:40:53,354 | INFO     | __main__ | [START TEST] torch.trtrs\n",
      "2025-07-24 18:40:59,451 | INFO     | __main__ | torch.trtrs в 1.0.0: Работает\n",
      "2025-07-24 18:41:09,580 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp6n274l3h.py\", line 1, in <module>\n",
      "    import torch; B = torch.tensor([[1.0], [2.0]]); A = torch.tensor([[1.0, 2.0], [0.0, 1.0]]); result = torch.trtrs(B, A); print('OK')\n",
      "                                                                                                         ^^^^^^^^^^^\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\__init__.py\", line 2688, in __getattr__\n",
      "    raise AttributeError(f\"module '{__name__}' has no attribute '{name}'\")\n",
      "AttributeError: module 'torch' has no attribute 'trtrs'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp6n274l3h.py` failed. (See above for error)\n",
      "2025-07-24 18:41:09,581 | INFO     | __main__ | torch.trtrs в 2.7.0: Не работает\n",
      "2025-07-24 18:41:10,019 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:41:56,007 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:41:56,010 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:42:06,289 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:42:06,291 | INFO     | __main__ | [END TEST] torch.trtrs\n",
      "2025-07-24 18:42:06,292 | INFO     | __main__ | [START TEST] torch.solve\n",
      "2025-07-24 18:42:12,469 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpmedqlnnu.py\", line 1, in <module>\n",
      "    import torch; A = torch.tensor([[1.0, 2.0], [3.0, 4.0]]); B = torch.tensor([[5.0], [6.0]]); result = torch.solve(B, A); print('OK')\n",
      "AttributeError: module 'torch' has no attribute 'solve'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpmedqlnnu.py` failed. (See above for error)\n",
      "2025-07-24 18:42:12,470 | INFO     | __main__ | torch.solve в 1.0.0: Не работает\n",
      "2025-07-24 18:42:22,884 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpkovdizs0.py\", line 1, in <module>\n",
      "    import torch; A = torch.tensor([[1.0, 2.0], [3.0, 4.0]]); B = torch.tensor([[5.0], [6.0]]); result = torch.solve(B, A); print('OK')\n",
      "                                                                                                         ~~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\_linalg_utils.py\", line 83, in solve\n",
      "    raise RuntimeError(\n",
      "    ...<7 lines>...\n",
      "    )\n",
      "RuntimeError: This function was deprecated since version 1.9 and is now removed. `torch.solve` is deprecated in favor of `torch.linalg.solve`. `torch.linalg.solve` has its arguments reversed and does not return the LU factorization.\n",
      "\n",
      "To get the LU factorization see `torch.lu`, which can be used with `torch.lu_solve` or `torch.lu_unpack`.\n",
      "X = torch.solve(B, A).solution should be replaced with:\n",
      "X = torch.linalg.solve(A, B)\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpkovdizs0.py` failed. (See above for error)\n",
      "2025-07-24 18:42:22,885 | INFO     | __main__ | torch.solve в 2.7.0: Не работает\n",
      "2025-07-24 18:42:23,289 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:42:41,859 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:42:41,863 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:42:52,063 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:42:52,064 | INFO     | __main__ | [END TEST] torch.solve\n",
      "2025-07-24 18:42:52,064 | INFO     | __main__ | [START TEST] torch.cholesky_solve\n",
      "2025-07-24 18:42:58,168 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpc800m2h_.py\", line 1, in <module>\n",
      "    import torch; B = torch.tensor([[1.0], [2.0]]); U = torch.tensor([[1.0, 2.0], [0.0, 1.0]]); result = torch.cholesky_solve(B, U); print('OK')\n",
      "AttributeError: module 'torch' has no attribute 'cholesky_solve'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpc800m2h_.py` failed. (See above for error)\n",
      "2025-07-24 18:42:58,170 | INFO     | __main__ | torch.cholesky_solve в 1.0.0: Не работает\n",
      "2025-07-24 18:43:08,523 | INFO     | __main__ | torch.cholesky_solve в 2.7.0: Работает\n",
      "2025-07-24 18:43:08,941 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:43:46,838 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:43:46,840 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:43:57,013 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:43:57,015 | INFO     | __main__ | [END TEST] torch.cholesky_solve\n",
      "2025-07-24 18:43:57,016 | INFO     | __main__ | [START TEST] torch.testing.make_tensor (low==high)\n",
      "2025-07-24 18:44:03,188 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp7ivu8a20.py\", line 1, in <module>\n",
      "    import torch.testing; t = torch.testing.make_tensor(5, low=1.0, high=1.0, dtype=torch.float32); print('OK')\n",
      "AttributeError: module 'torch.testing' has no attribute 'make_tensor'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp7ivu8a20.py` failed. (See above for error)\n",
      "2025-07-24 18:44:03,191 | INFO     | __main__ | torch.testing.make_tensor (low==high) в 1.0.0: Не работает\n",
      "2025-07-24 18:44:13,366 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmppi6olq_8.py\", line 1, in <module>\n",
      "    import torch.testing; t = torch.testing.make_tensor(5, low=1.0, high=1.0, dtype=torch.float32); print('OK')\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: make_tensor() missing 1 required keyword-only argument: 'device'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmppi6olq_8.py` failed. (See above for error)\n",
      "2025-07-24 18:44:13,367 | INFO     | __main__ | torch.testing.make_tensor (low==high) в 2.7.0: Не работает\n",
      "2025-07-24 18:44:13,661 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:44:59,563 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:44:59,564 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:45:09,814 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpnnsdib3p.py\", line 2, in <module>\n",
      "    t = torch.testing.make_tensor((5,), low=1.0, high=1.0, dtype=torch.float32)\n",
      "TypeError: make_tensor() missing 1 required keyword-only argument: 'device'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpnnsdib3p.py` failed. (See above for error)\n",
      "2025-07-24 18:45:09,815 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Не работает\n",
      "2025-07-24 18:45:09,816 | INFO     | __main__ | [END TEST] torch.testing.make_tensor (low==high)\n",
      "2025-07-24 18:45:09,816 | INFO     | __main__ | [START TEST] torch.nn.Module.register_backward_hook\n",
      "2025-07-24 18:45:15,834 | INFO     | __main__ | torch.nn.Module.register_backward_hook в 1.0.0: Работает\n",
      "2025-07-24 18:45:26,223 | INFO     | __main__ | torch.nn.Module.register_backward_hook в 2.7.0: Работает\n",
      "2025-07-24 18:45:26,616 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:45:51,713 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:45:51,717 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:46:01,956 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:46:01,958 | INFO     | __main__ | [END TEST] torch.nn.Module.register_backward_hook\n",
      "2025-07-24 18:46:01,958 | INFO     | __main__ | [START TEST] torch._export.capture_pre_autograd_graph\n",
      "2025-07-24 18:46:07,648 | ERROR    | validator | Oшибка при исполнении code: File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp8wbv21a6.py\", line 1\n",
      "    from torch._export import capture_pre_autograd_graph; import torch; def f(x): return x * 2; captured = capture_pre_autograd_graph(f, (torch.tensor(1.0),)); print('OK')\n",
      "                                                                          ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp8wbv21a6.py` failed. (See above for error)\n",
      "2025-07-24 18:46:07,649 | INFO     | __main__ | torch._export.capture_pre_autograd_graph в 1.0.0: Не работает\n",
      "2025-07-24 18:46:15,550 | ERROR    | validator | Oшибка при исполнении code: File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpoqtlqdty.py\", line 1\n",
      "    from torch._export import capture_pre_autograd_graph; import torch; def f(x): return x * 2; captured = capture_pre_autograd_graph(f, (torch.tensor(1.0),)); print('OK')\n",
      "                                                                        ^^^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpoqtlqdty.py` failed. (See above for error)\n",
      "2025-07-24 18:46:15,551 | INFO     | __main__ | torch._export.capture_pre_autograd_graph в 2.7.0: Не работает\n",
      "2025-07-24 18:46:15,940 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:47:54,844 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:47:54,846 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:48:08,673 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpl7ylow6o.py\", line 5, in <module>\n",
      "    captured = export(f, (torch.tensor(1.0),))\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\export\\__init__.py\", line 351, in export\n",
      "    raise ValueError(\n",
      "        f\"Expected `mod` to be an instance of `torch.nn.Module`, got {type(mod)}.\"\n",
      "    )\n",
      "ValueError: Expected `mod` to be an instance of `torch.nn.Module`, got <class 'function'>.\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpl7ylow6o.py` failed. (See above for error)\n",
      "2025-07-24 18:48:08,676 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Не работает\n",
      "2025-07-24 18:48:08,677 | INFO     | __main__ | [END TEST] torch._export.capture_pre_autograd_graph\n",
      "2025-07-24 18:48:08,678 | INFO     | __main__ | [START TEST] torch.distributed.init_process_group (old backend)\n",
      "2025-07-24 18:48:14,669 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpjomjj7iq.py\", line 1, in <module>\n",
      "    import torch.distributed as dist; dist.init_process_group(backend='gloo', init_method='tcp://127.0.0.1:12345', world_size=1, rank=0); print('OK')\n",
      "AttributeError: module 'torch.distributed' has no attribute 'init_process_group'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpjomjj7iq.py` failed. (See above for error)\n",
      "2025-07-24 18:48:14,670 | INFO     | __main__ | torch.distributed.init_process_group (old backend) в 1.0.0: Не работает\n",
      "2025-07-24 18:48:24,694 | INFO     | __main__ | torch.distributed.init_process_group (old backend) в 2.7.0: Не работает\n",
      "2025-07-24 18:48:25,078 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:48:54,120 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:48:54,121 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:49:04,114 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Не работает\n",
      "2025-07-24 18:49:04,116 | INFO     | __main__ | [END TEST] torch.distributed.init_process_group (old backend)\n",
      "2025-07-24 18:49:04,118 | INFO     | __main__ | [START TEST] torch.optim.LBFGS (old params)\n",
      "2025-07-24 18:49:10,075 | INFO     | __main__ | torch.optim.LBFGS (old params) в 1.0.0: Работает\n",
      "2025-07-24 18:49:21,723 | INFO     | __main__ | torch.optim.LBFGS (old params) в 2.7.0: Работает\n",
      "2025-07-24 18:49:22,059 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:50:14,475 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:50:14,476 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:50:26,144 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:50:26,145 | INFO     | __main__ | [END TEST] torch.optim.LBFGS (old params)\n",
      "2025-07-24 18:50:26,146 | INFO     | __main__ | [START TEST] torch.linalg.qr\n",
      "2025-07-24 18:50:32,244 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpb_rpgvij.py\", line 1, in <module>\n",
      "    import torch; a = torch.randn(3,3); q, r = torch.linalg.qr(a); print('OK')\n",
      "AttributeError: module 'torch' has no attribute 'linalg'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpb_rpgvij.py` failed. (See above for error)\n",
      "2025-07-24 18:50:32,245 | INFO     | __main__ | torch.linalg.qr в 1.0.0: Не работает\n",
      "2025-07-24 18:50:42,300 | INFO     | __main__ | torch.linalg.qr в 2.7.0: Работает\n",
      "2025-07-24 18:50:42,543 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:51:16,937 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:51:16,940 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:51:26,968 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:51:26,969 | INFO     | __main__ | [END TEST] torch.linalg.qr\n",
      "2025-07-24 18:51:26,970 | INFO     | __main__ | [START TEST] torch.linalg.solve\n",
      "2025-07-24 18:51:32,944 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpmjogk0zg.py\", line 1, in <module>\n",
      "    import torch; a = torch.randn(3,3); b = torch.randn(3,1); solution = torch.linalg.solve(a, b); print('OK')\n",
      "AttributeError: module 'torch' has no attribute 'linalg'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpmjogk0zg.py` failed. (See above for error)\n",
      "2025-07-24 18:51:32,945 | INFO     | __main__ | torch.linalg.solve в 1.0.0: Не работает\n",
      "2025-07-24 18:51:42,991 | INFO     | __main__ | torch.linalg.solve в 2.7.0: Работает\n",
      "2025-07-24 18:51:43,329 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:52:20,605 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:52:20,606 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:52:30,671 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:52:30,672 | INFO     | __main__ | [END TEST] torch.linalg.solve\n",
      "2025-07-24 18:52:30,673 | INFO     | __main__ | [START TEST] torch.linalg.cholesky_inverse\n",
      "2025-07-24 18:52:36,770 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmppi6dc0dx.py\", line 1, in <module>\n",
      "    import torch; a = torch.randn(3,3); pos_def = a @ a.t() + torch.eye(3); chol = torch.linalg.cholesky(pos_def); inv = torch.linalg.cholesky_inverse(chol); print('OK')\n",
      "AttributeError: module 'torch' has no attribute 'linalg'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmppi6dc0dx.py` failed. (See above for error)\n",
      "2025-07-24 18:52:36,772 | INFO     | __main__ | torch.linalg.cholesky_inverse в 1.0.0: Не работает\n",
      "2025-07-24 18:52:46,814 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp8jx6yk2n.py\", line 1, in <module>\n",
      "    import torch; a = torch.randn(3,3); pos_def = a @ a.t() + torch.eye(3); chol = torch.linalg.cholesky(pos_def); inv = torch.linalg.cholesky_inverse(chol); print('OK')\n",
      "                                                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'torch.linalg' has no attribute 'cholesky_inverse'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp8jx6yk2n.py` failed. (See above for error)\n",
      "2025-07-24 18:52:46,816 | INFO     | __main__ | torch.linalg.cholesky_inverse в 2.7.0: Не работает\n",
      "2025-07-24 18:52:47,180 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:53:15,065 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:53:15,067 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:53:25,449 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpfkzge_es.py\", line 5, in <module>\n",
      "    inv = torch.linalg.cholesky_inverse(chol)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'torch.linalg' has no attribute 'cholesky_inverse'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpfkzge_es.py` failed. (See above for error)\n",
      "2025-07-24 18:53:25,450 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Не работает\n",
      "2025-07-24 18:53:25,451 | INFO     | __main__ | [END TEST] torch.linalg.cholesky_inverse\n",
      "2025-07-24 18:53:25,452 | INFO     | __main__ | [START TEST] torch.triangular_solve\n",
      "2025-07-24 18:53:31,601 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpnw_xr4ms.py\", line 1, in <module>\n",
      "    import torch; a = torch.triu(torch.randn(3,3)); b = torch.randn(3,1); solution, cloned_a = torch.triangular_solve(b, a); print('OK')\n",
      "AttributeError: module 'torch' has no attribute 'triangular_solve'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpnw_xr4ms.py` failed. (See above for error)\n",
      "2025-07-24 18:53:31,602 | INFO     | __main__ | torch.triangular_solve в 1.0.0: Не работает\n",
      "2025-07-24 18:53:42,038 | INFO     | __main__ | torch.triangular_solve в 2.7.0: Не работает\n",
      "2025-07-24 18:53:42,393 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:54:04,249 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:54:04,254 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:54:14,344 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Работает\n",
      "2025-07-24 18:54:14,345 | INFO     | __main__ | [END TEST] torch.triangular_solve\n",
      "2025-07-24 18:54:14,346 | INFO     | __main__ | [START TEST] torch.export.export\n",
      "2025-07-24 18:54:20,069 | ERROR    | validator | Oшибка при исполнении code: File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpuozseamm.py\", line 1\n",
      "    import torch; def f(x): return x * 2; exported = torch.export.export(f, (torch.tensor(1.0),)); print('OK')\n",
      "                    ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpuozseamm.py` failed. (See above for error)\n",
      "2025-07-24 18:54:20,070 | INFO     | __main__ | torch.export.export в 1.0.0: Не работает\n",
      "2025-07-24 18:54:27,873 | ERROR    | validator | Oшибка при исполнении code: File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmposajnxzp.py\", line 1\n",
      "    import torch; def f(x): return x * 2; exported = torch.export.export(f, (torch.tensor(1.0),)); print('OK')\n",
      "                  ^^^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmposajnxzp.py` failed. (See above for error)\n",
      "2025-07-24 18:54:27,874 | INFO     | __main__ | torch.export.export в 2.7.0: Не работает\n",
      "2025-07-24 18:54:28,138 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:55:30,466 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:55:30,469 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:55:43,065 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpkccym5v0.py\", line 4, in <module>\n",
      "    exported = torch.export.export(f, (torch.tensor(1.0),))\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\export\\__init__.py\", line 351, in export\n",
      "    raise ValueError(\n",
      "        f\"Expected `mod` to be an instance of `torch.nn.Module`, got {type(mod)}.\"\n",
      "    )\n",
      "ValueError: Expected `mod` to be an instance of `torch.nn.Module`, got <class 'function'>.\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpkccym5v0.py` failed. (See above for error)\n",
      "2025-07-24 18:55:43,069 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Не работает\n",
      "2025-07-24 18:55:43,070 | INFO     | __main__ | [END TEST] torch.export.export\n",
      "2025-07-24 18:55:43,073 | INFO     | __main__ | [START TEST] torch.distributed.init_process_group (nccl backend)\n",
      "2025-07-24 18:55:49,189 | ERROR    | validator | Oшибка при исполнении code: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp29qf4c08.py\", line 1, in <module>\n",
      "    import torch.distributed as dist; dist.init_process_group(backend='nccl', init_method='tcp://127.0.0.1:12346', world_size=1, rank=0); print('OK')\n",
      "AttributeError: module 'torch.distributed' has no attribute 'init_process_group'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp29qf4c08.py` failed. (See above for error)\n",
      "2025-07-24 18:55:49,190 | INFO     | __main__ | torch.distributed.init_process_group (nccl backend) в 1.0.0: Не работает\n",
      "2025-07-24 18:55:59,321 | ERROR    | validator | Oшибка при исполнении code: C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py:746: UserWarning: Attempted to get default timeout for nccl backend, but NCCL support is not compiled\n",
      "  warnings.warn(\n",
      "[W724 18:55:58.000000000 socket.cpp:755] [c10d] The client socket has failed to connect to [kubernetes.docker.internal]:12346 (system error: 10049 - ��������� ����� ��� ������ ��������� �������.).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpueyr1bez.py\", line 1, in <module>\n",
      "    import torch.distributed as dist; dist.init_process_group(backend='nccl', init_method='tcp://127.0.0.1:12346', world_size=1, rank=0); print('OK')\n",
      "                                      ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 81, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 95, in wrapper\n",
      "    func_return = func(*args, **kwargs)\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1717, in init_process_group\n",
      "    default_pg, _ = _new_process_group_helper(\n",
      "                    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        world_size,\n",
      "        ^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "        group_desc=\"default_pg\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1948, in _new_process_group_helper\n",
      "    raise RuntimeError(\"Distributed package doesn't have NCCL built in\")\n",
      "RuntimeError: Distributed package doesn't have NCCL built in\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpueyr1bez.py` failed. (See above for error)\n",
      "2025-07-24 18:55:59,322 | INFO     | __main__ | torch.distributed.init_process_group (nccl backend) в 2.7.0: Не работает\n",
      "2025-07-24 18:55:59,713 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-24 18:57:07,474 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-24 18:57:07,475 | INFO     | __main__ | Получен код из ответа LLM\n",
      "2025-07-24 18:57:17,933 | ERROR    | validator | Oшибка при исполнении code: C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py:746: UserWarning: Attempted to get default timeout for nccl backend, but NCCL support is not compiled\n",
      "  warnings.warn(\n",
      "[W724 18:57:17.000000000 socket.cpp:755] [c10d] The client socket has failed to connect to [kubernetes.docker.internal]:12346 (system error: 10049 - ��������� ����� ��� ������ ��������� �������.).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpxq746ku8.py\", line 2, in <module>\n",
      "    dist.init_process_group(backend='nccl', init_method='tcp://127.0.0.1:12346', world_size=1, rank=0)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 81, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 95, in wrapper\n",
      "    func_return = func(*args, **kwargs)\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1717, in init_process_group\n",
      "    default_pg, _ = _new_process_group_helper(\n",
      "                    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        world_size,\n",
      "        ^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "        group_desc=\"default_pg\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1948, in _new_process_group_helper\n",
      "    raise RuntimeError(\"Distributed package doesn't have NCCL built in\")\n",
      "RuntimeError: Distributed package doesn't have NCCL built in\n",
      "\n",
      "ERROR conda.cli.main_run:execute(127): `conda run python C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpxq746ku8.py` failed. (See above for error)\n",
      "2025-07-24 18:57:17,934 | INFO     | __main__ | Вариант предложенный RAG в 2.7.0: Не работает\n",
      "2025-07-24 18:57:17,935 | INFO     | __main__ | [END TEST] torch.distributed.init_process_group (nccl backend)\n"
     ]
    }
   ],
   "source": [
    "info_dicts = []\n",
    "code_dicts = []\n",
    "\n",
    "for name, old_code in TESTS_DICT.items():\n",
    "    new_code = RAG_get_new_code(old_code, LLM_NAME)\n",
    "    info_dict, dict_code = val.run_test_old_and_new_code(name, old_code, new_code)\n",
    "\n",
    "    info_dicts.append(info_dict)\n",
    "    code_dicts.append(dict_code)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa66708",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "606e90b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>API</th>\n",
       "      <th>Работает в 1.0.0</th>\n",
       "      <th>Out 1.0.0</th>\n",
       "      <th>Err 1.0.0</th>\n",
       "      <th>Работает в 2.7.0</th>\n",
       "      <th>Out 2.7.0</th>\n",
       "      <th>Err 2.7.0</th>\n",
       "      <th>Работает в 2.7.0 (после RAG)</th>\n",
       "      <th>RAG Out 2.7.0</th>\n",
       "      <th>RAG Err 2.7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>torch._six</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>torch.qr</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "      <td>C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpnnffnk5j....</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>torch.autograd.function.traceable</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>torch.testing.make_non_contiguous</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>torch.gesv</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>torch.potri</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>torch.potrs</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>torch.trtrs</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>torch.solve</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>torch.cholesky_solve</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>torch.testing.make_tensor (low==high)</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>torch.nn.Module.register_backward_hook</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>torch._export.capture_pre_autograd_graph</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp8wb...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpoqt...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>torch.distributed.init_process_group (old back...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "      <td>[W724 18:48:24.000000000 socket.cpp:755] [c10d...</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "      <td>[W724 18:49:03.000000000 socket.cpp:755] [c10d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>torch.optim.LBFGS (old params)</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>torch.linalg.qr</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>torch.linalg.solve</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>torch.linalg.cholesky_inverse</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>torch.triangular_solve</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "      <td>C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpv_6mwech....</td>\n",
       "      <td>True</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>torch.export.export</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpuoz...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmposa...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>torch.distributed.init_process_group (nccl bac...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                                API  \\\n",
       "0            0                                         torch._six   \n",
       "1            1                                           torch.qr   \n",
       "2            2                  torch.autograd.function.traceable   \n",
       "3            3                  torch.testing.make_non_contiguous   \n",
       "4            4                                         torch.gesv   \n",
       "5            5                                        torch.potri   \n",
       "6            6                                        torch.potrs   \n",
       "7            7                                        torch.trtrs   \n",
       "8            8                                        torch.solve   \n",
       "9            9                               torch.cholesky_solve   \n",
       "10          10              torch.testing.make_tensor (low==high)   \n",
       "11          11             torch.nn.Module.register_backward_hook   \n",
       "12          12           torch._export.capture_pre_autograd_graph   \n",
       "13          13  torch.distributed.init_process_group (old back...   \n",
       "14          14                     torch.optim.LBFGS (old params)   \n",
       "15          15                                    torch.linalg.qr   \n",
       "16          16                                 torch.linalg.solve   \n",
       "17          17                      torch.linalg.cholesky_inverse   \n",
       "18          18                             torch.triangular_solve   \n",
       "19          19                                torch.export.export   \n",
       "20          20  torch.distributed.init_process_group (nccl bac...   \n",
       "\n",
       "    Работает в 1.0.0 Out 1.0.0  \\\n",
       "0               True        OK   \n",
       "1               True        OK   \n",
       "2               True     False   \n",
       "3               True        OK   \n",
       "4               True        OK   \n",
       "5               True        OK   \n",
       "6               True        OK   \n",
       "7               True        OK   \n",
       "8              False       NaN   \n",
       "9              False       NaN   \n",
       "10             False       NaN   \n",
       "11              True        OK   \n",
       "12             False       NaN   \n",
       "13             False       NaN   \n",
       "14              True        OK   \n",
       "15             False       NaN   \n",
       "16             False       NaN   \n",
       "17             False       NaN   \n",
       "18             False       NaN   \n",
       "19             False       NaN   \n",
       "20             False       NaN   \n",
       "\n",
       "                                            Err 1.0.0  Работает в 2.7.0  \\\n",
       "0                                                 NaN             False   \n",
       "1                                                 NaN             False   \n",
       "2                                                 NaN              True   \n",
       "3                                                 NaN             False   \n",
       "4                                                 NaN             False   \n",
       "5                                                 NaN             False   \n",
       "6                                                 NaN             False   \n",
       "7                                                 NaN             False   \n",
       "8   Traceback (most recent call last):\\n  File \"C:...             False   \n",
       "9   Traceback (most recent call last):\\n  File \"C:...              True   \n",
       "10  Traceback (most recent call last):\\n  File \"C:...             False   \n",
       "11                                                NaN              True   \n",
       "12  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmp8wb...             False   \n",
       "13  Traceback (most recent call last):\\n  File \"C:...             False   \n",
       "14                                                NaN              True   \n",
       "15  Traceback (most recent call last):\\n  File \"C:...              True   \n",
       "16  Traceback (most recent call last):\\n  File \"C:...              True   \n",
       "17  Traceback (most recent call last):\\n  File \"C:...             False   \n",
       "18  Traceback (most recent call last):\\n  File \"C:...             False   \n",
       "19  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpuoz...             False   \n",
       "20  Traceback (most recent call last):\\n  File \"C:...             False   \n",
       "\n",
       "   Out 2.7.0                                          Err 2.7.0  \\\n",
       "0        NaN  Traceback (most recent call last):\\n  File \"C:...   \n",
       "1         OK  C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpnnffnk5j....   \n",
       "2      False                                                NaN   \n",
       "3        NaN  Traceback (most recent call last):\\n  File \"C:...   \n",
       "4        NaN  Traceback (most recent call last):\\n  File \"C:...   \n",
       "5        NaN  Traceback (most recent call last):\\n  File \"C:...   \n",
       "6        NaN  Traceback (most recent call last):\\n  File \"C:...   \n",
       "7        NaN  Traceback (most recent call last):\\n  File \"C:...   \n",
       "8        NaN  Traceback (most recent call last):\\n  File \"C:...   \n",
       "9         OK                                                NaN   \n",
       "10       NaN  Traceback (most recent call last):\\n  File \"C:...   \n",
       "11        OK                                                NaN   \n",
       "12       NaN  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpoqt...   \n",
       "13        OK  [W724 18:48:24.000000000 socket.cpp:755] [c10d...   \n",
       "14        OK                                                NaN   \n",
       "15        OK                                                NaN   \n",
       "16        OK                                                NaN   \n",
       "17       NaN  Traceback (most recent call last):\\n  File \"C:...   \n",
       "18        OK  C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpv_6mwech....   \n",
       "19       NaN  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmposa...   \n",
       "20       NaN  C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\...   \n",
       "\n",
       "    Работает в 2.7.0 (после RAG) RAG Out 2.7.0  \\\n",
       "0                           True            OK   \n",
       "1                           True            OK   \n",
       "2                           True         False   \n",
       "3                           True            OK   \n",
       "4                           True            OK   \n",
       "5                           True            OK   \n",
       "6                           True            OK   \n",
       "7                           True            OK   \n",
       "8                           True            OK   \n",
       "9                           True            OK   \n",
       "10                         False           NaN   \n",
       "11                          True            OK   \n",
       "12                         False           NaN   \n",
       "13                         False            OK   \n",
       "14                          True            OK   \n",
       "15                          True            OK   \n",
       "16                          True            OK   \n",
       "17                          True            OK   \n",
       "18                          True            OK   \n",
       "19                         False           NaN   \n",
       "20                         False           NaN   \n",
       "\n",
       "                                        RAG Err 2.7.0  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10  Traceback (most recent call last):\\n  File \"C:...  \n",
       "11                                                NaN  \n",
       "12  Traceback (most recent call last):\\n  File \"C:...  \n",
       "13  [W724 18:49:03.000000000 socket.cpp:755] [c10d...  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19  Traceback (most recent call last):\\n  File \"C:...  \n",
       "20  C:\\Miniconda3\\envs\\torch270\\Lib\\site-packages\\...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfTest = pd.DataFrame(info_dicts)\n",
    "dfTest = pd.read_csv(\"results_testing.csv\")\n",
    "dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1e9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830091d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is work in 1.0.0</th>\n",
       "      <th>Is work in 1.0.0 (%)</th>\n",
       "      <th>Is work in 2.7.0</th>\n",
       "      <th>Is work in 2.7.0 (%)</th>\n",
       "      <th>Is work in 2.7.0 (RAG)</th>\n",
       "      <th>Is work in 2.7.0 (RAG) (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BAAI_bge-base-en.csv</th>\n",
       "      <td>10</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>6</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>14</td>\n",
       "      <td>73.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAAI_bge-large-en.csv</th>\n",
       "      <td>10</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>6</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>15</td>\n",
       "      <td>78.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat_e5-large.csv</th>\n",
       "      <td>10</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>6</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>16</td>\n",
       "      <td>84.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers_all-MiniLM-L6-v2.csv</th>\n",
       "      <td>10</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>6</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>17</td>\n",
       "      <td>89.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers_LaBSE.csv</th>\n",
       "      <td>10</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>6</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>16</td>\n",
       "      <td>84.210526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Is work in 1.0.0  \\\n",
       "BAAI_bge-base-en.csv                                      10   \n",
       "BAAI_bge-large-en.csv                                     10   \n",
       "intfloat_e5-large.csv                                     10   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                10   \n",
       "sentence-transformers_LaBSE.csv                           10   \n",
       "\n",
       "                                            Is work in 1.0.0 (%)  \\\n",
       "BAAI_bge-base-en.csv                                   52.631579   \n",
       "BAAI_bge-large-en.csv                                  52.631579   \n",
       "intfloat_e5-large.csv                                  52.631579   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv             52.631579   \n",
       "sentence-transformers_LaBSE.csv                        52.631579   \n",
       "\n",
       "                                            Is work in 2.7.0  \\\n",
       "BAAI_bge-base-en.csv                                       6   \n",
       "BAAI_bge-large-en.csv                                      6   \n",
       "intfloat_e5-large.csv                                      6   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                 6   \n",
       "sentence-transformers_LaBSE.csv                            6   \n",
       "\n",
       "                                            Is work in 2.7.0 (%)  \\\n",
       "BAAI_bge-base-en.csv                                   31.578947   \n",
       "BAAI_bge-large-en.csv                                  31.578947   \n",
       "intfloat_e5-large.csv                                  31.578947   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv             31.578947   \n",
       "sentence-transformers_LaBSE.csv                        31.578947   \n",
       "\n",
       "                                            Is work in 2.7.0 (RAG)  \\\n",
       "BAAI_bge-base-en.csv                                            14   \n",
       "BAAI_bge-large-en.csv                                           15   \n",
       "intfloat_e5-large.csv                                           16   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                      17   \n",
       "sentence-transformers_LaBSE.csv                                 16   \n",
       "\n",
       "                                            Is work in 2.7.0 (RAG) (%)  \n",
       "BAAI_bge-base-en.csv                                         73.684211  \n",
       "BAAI_bge-large-en.csv                                        78.947368  \n",
       "intfloat_e5-large.csv                                        84.210526  \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                   89.473684  \n",
       "sentence-transformers_LaBSE.csv                              84.210526  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def analyz_test():\n",
    "    csv_files = glob.glob(\"*.csv\", root_dir=\"data/\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        dfTest = pd.read_csv(\"data/\"+csv_file)\n",
    "        сount_test = len(dfTest)\n",
    "\n",
    "        count_works_1_0 = dfTest['Is work in 1.0.0'].sum()\n",
    "        count_works_2_7 = dfTest['Is work in 2.7.0'].sum()\n",
    "        count_rag_2_7 = dfTest['Is work in 2.7.0 (после RAG)'].sum()\n",
    "\n",
    "        pct_works_1_0 = (count_works_1_0 / сount_test) * 100\n",
    "        pct_works_2_7 = (count_works_2_7 / сount_test) * 100\n",
    "        pct_rag_2_7 = (count_rag_2_7 / сount_test) * 100\n",
    "\n",
    "        result_dict = {\n",
    "            \"Is work in 1.0.0\": count_works_1_0,\n",
    "            \"Is work in 1.0.0 (%)\": pct_works_1_0,\n",
    "            \"Is work in 2.7.0\": count_works_2_7,\n",
    "            \"Is work in 2.7.0 (%)\": pct_works_2_7,\n",
    "            \"Is work in 2.7.0 (RAG)\": count_rag_2_7,\n",
    "            \"Is work in 2.7.0 (RAG) (%)\": pct_rag_2_7,\n",
    "        }\n",
    "\n",
    "        results.append(result_dict)\n",
    "    \n",
    "    return pd.DataFrame(results, index=csv_files)\n",
    "\n",
    "analyz_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499729be",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "migratetorch_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
