{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40530bd",
   "metadata": {},
   "source": [
    "# Тема 'RAG для миграции pyTorch с v1.0.0 на v2.7.0' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c203cc94",
   "metadata": {},
   "source": [
    "## Настройка для использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe282da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 13:25:18,630 | INFO     | __main__ | Модель intfloat/e5-large загружена\n",
      "2025-07-27 13:25:22,191 | INFO     | __main__ | БД подключена\n"
     ]
    }
   ],
   "source": [
    "from logs.logging_setup import configure_logging\n",
    "configure_logging()\n",
    "import logging\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "from validator import Validator\n",
    "from retrival import Retreiver, get_embedding_core\n",
    "from llm import get_llm_response, clean_llm_code\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "LLM_NAME = \"tngtech/deepseek-r1t2-chimera\"\n",
    "\n",
    "# =========  Загрузка модели =================\n",
    "model, tokenizer = get_embedding_core(\"intfloat/e5-large\")\n",
    "LOGGER.info(f\"Модель {model.model_name} загружена\")\n",
    "\n",
    "# =========  Подключение к БД =================\n",
    "rtr = Retreiver(model, model.model_name)\n",
    "LOGGER.info(f\"БД подключена\")\n",
    "\n",
    "# =========  Инициализация валидатора =================\n",
    "val = Validator()\n",
    "\n",
    "def RAG_get_new_code(code, model_name):\n",
    "    '''\n",
    "        Получаем новый код после прогана в RAG\n",
    "    '''\n",
    "    prompt = rtr.build_prompt(code)\n",
    "    LOGGER.info(f\"Запрос в БД успешно выполнен\")\n",
    "\n",
    "    result = get_llm_response(prompt, model_name=model_name)\n",
    "    LOGGER.info(f\"Запрос в LLM успешно выполнен\")\n",
    "\n",
    "    result_code, explanation = clean_llm_code(result)\n",
    "    LOGGER.info(f\"Получен код из ответа LLM\")\n",
    "\n",
    "    return result_code, explanation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be239e5d",
   "metadata": {},
   "source": [
    "## **Что такое RAG и почему он нужен бизнесу**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c11caa",
   "metadata": {},
   "source": [
    "![Репозитории в gitHub](data\\image\\more_rag_github.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8201322",
   "metadata": {},
   "source": [
    "RAG (Retrieval Augmented Generation) — это метод работы с большими языковыми моделями, когда пользователь пишет свой вопросы, а мы программно к этому вопросу «подмешиваете» дополнительную информацию из каких‑то внешних источников и подаём все целиком на вход языковой модели. Другими словами мы говорим, то о чём наша модель может не знать или \"забыть\" это учесть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d196f1",
   "metadata": {},
   "source": [
    "**Давайте разберём на примере:**\n",
    "\n",
    "*Пользователь*: Какой должен быть шрифт у кода при написании дипломной работы в ОГУ? \n",
    "\n",
    "LLM это не знает с вероятностью почти в 100% и тут появляется несколько исходов у LLM.\n",
    "1) Сказать честно, что она не знает\n",
    "2) Придумать свой вариант\n",
    "3) Найти из интернета, но не факт, что она обратится к нужному источнику для поиска информации.\n",
    "\n",
    "И тут на помощь приходит RAG, он дополняет вопрос пользователя. И поможет LLM ответить правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2d7ba",
   "metadata": {},
   "source": [
    "![Всё хорошо](data\\image\\all_good.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947532e",
   "metadata": {},
   "source": [
    "## Что он может(на данный момент)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfcd93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"torch._six\"\n",
    "old_code = \"\"\"\n",
    "torch.distributed.init_process_grou\": \"import torch.distributed as dist; dist.init_process_group(backend='gloo', init_method='tcp://127.0.0.1:12345', world_size=1, rank=0); print('OK')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ba09cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 16:39:06,515 | INFO     | __main__ | Запрос в БД успешно выполнен\n",
      "2025-07-26 16:39:50,045 | INFO     | __main__ | Запрос в LLM успешно выполнен\n",
      "2025-07-26 16:39:50,046 | INFO     | __main__ | Получен код из ответа LLM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Old code:\n",
      " \n",
      "torch.distributed.init_process_grou\": \"import torch.distributed as dist; dist.init_process_group(backend='gloo', init_method='tcp://127.0.0.1:12345', world_size=1, rank=0); print('OK')\n",
      "\n",
      "==============================\n",
      "New code:\n",
      " import torch.distributed as dist\n",
      "dist.init_process_group(\n",
      "    backend='gloo',\n",
      "    init_method='tcp://127.0.0.1:12345',\n",
      "    world_size=1,\n",
      "    rank=0\n",
      ")\n",
      "print('OK')\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API</th>\n",
       "      <th>Работает в 1.0.0</th>\n",
       "      <th>Out 1.0.0</th>\n",
       "      <th>Err 1.0.0</th>\n",
       "      <th>Работает в 2.7.0</th>\n",
       "      <th>Out 2.7.0</th>\n",
       "      <th>Err 2.7.0</th>\n",
       "      <th>Работает в 2.7.0 (после RAG)</th>\n",
       "      <th>RAG Out 2.7.0</th>\n",
       "      <th>RAG Err 2.7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>torch._six</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpya1...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpetn...</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "      <td>[W726 16:40:16.000000000 socket.cpp:755] [c10d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             API  Работает в 1.0.0 Out 1.0.0  \\\n",
       "Test  torch._six             False             \n",
       "\n",
       "                                              Err 1.0.0  Работает в 2.7.0  \\\n",
       "Test  File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpya1...             False   \n",
       "\n",
       "     Out 2.7.0                                          Err 2.7.0  \\\n",
       "Test            File \"C:\\Users\\sinde\\AppData\\Local\\Temp\\tmpetn...   \n",
       "\n",
       "      Работает в 2.7.0 (после RAG) RAG Out 2.7.0  \\\n",
       "Test                         False            OK   \n",
       "\n",
       "                                          RAG Err 2.7.0  \n",
       "Test  [W726 16:40:16.000000000 socket.cpp:755] [c10d...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_code = RAG_get_new_code(old_code, LLM_NAME)\n",
    "dict_info, dict_code = val.run_test_old_and_new_code(name, old_code, new_code)\n",
    "\n",
    "print('='*30)\n",
    "print('Old code:\\n',dict_code['old_code'])\n",
    "print('='*30)\n",
    "print('New code:\\n',dict_code['new_code'])\n",
    "print('='*30)\n",
    "\n",
    "pd.DataFrame(dict_info, index=['Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca20b61",
   "metadata": {},
   "source": [
    "## Обзор архитектуры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1904dacc",
   "metadata": {},
   "source": [
    "### **Откуда мы брали данные и почему именно эти данные?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a98d8a",
   "metadata": {},
   "source": [
    "Прежде чем приступать к архитектуре, давайте так же затронем не мало важную тему.\n",
    "\n",
    "СБОР ДАННЫХ!!\n",
    "\n",
    "\n",
    "Да, сбор данных это одна из важнейших ступеней в построении хорошей RAG системы. А всё потому что вы можете сделать ЛУЧШУЮ архитектуру, ЛУЧШИЕ методы поиска информации, ЛУЧШАЯ LLM, ЛУЧШИЙ промт, ЛУЧШИЙ UI... Ну ладно UI это конечно лишние.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a9fda",
   "metadata": {},
   "source": [
    "![image.png](data\\image\\git_pyTorch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b66892",
   "metadata": {},
   "source": [
    "Все данные для создания контекста мы взяли из рилизов опубликованных на [gitHub](https://github.com/pytorch/pytorch/releases)\n",
    "\n",
    "\n",
    "Они идеально подходят для нашей задачи, так как в рилизах прописываются изменения api, а так же есть примеры написания кода, а так же прописывается номер версии. \n",
    "\n",
    "Идеи по улучшению: \n",
    "* Можно добавить документацию по каждой из версий. Это даст больший контекст.\n",
    "* Можно добавить данные из stackOverflou, но их нужно размечать(трудозатратно)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f9330",
   "metadata": {},
   "source": [
    "### **Основные компоненты RAG** + (стэк технологий)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48fbf9",
   "metadata": {},
   "source": [
    "Давайте рассмотрим процесс создания RAG целиком, а потом начнём разбирать каждый элемент в отдельности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0f01a",
   "metadata": {},
   "source": [
    "![RAG](data\\image\\rag_scheme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec889bdd",
   "metadata": {},
   "source": [
    "Разберём препроцессинг "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc6b8a",
   "metadata": {},
   "source": [
    "![Pre-processing](data\\image\\rag_scheme_pre_processing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8622e06f",
   "metadata": {},
   "source": [
    "Подготовка данных:\n",
    "\n",
    "**User Documents:** В нашем случае это рилизы из gitHub\n",
    "\n",
    "**Далее, chunking:** Я выбрал RecursiveCharacterTextSplitter из LangChain, потому что он предлагает гибкий и семантически осмысленный подход к разбиению текста.python.langchain.com Этот сплиттер рекурсивно делит текст по иерархии разделителей (например, сначала по абзацам, затем по предложениям, словам или символам)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee601a1",
   "metadata": {},
   "source": [
    "Для embedding я выбрал модель e5-large-v2, которая лидирует в [MTEB leaderboard](https://modal.com/blog/embedding-models-article). \n",
    "\n",
    "Почему именно она? \n",
    "Эта модель компактна, быстрая в inference, и показывает высокую семантическую схожесть - ключ для RAG, где эмбеддинги должны захватывать нюансы языка. Интегрируется напрямую с LangChain. (Это очень важно для нас, так как подключаемся к БД мы с помощью langChain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c9ed6",
   "metadata": {},
   "source": [
    "Наконец, хранение эмбеддингов: \n",
    "Я использую QDrant в комбинации с LangChain, потому что QDrant - это **AI-native vector database**, оптимизированная для семантического поиска. Интеграция с LangChain проста, через QdrantVectorStore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0ec1e",
   "metadata": {},
   "source": [
    "Теперь мы перейдём к ретривалу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c7717",
   "metadata": {},
   "source": [
    "![Retrieval](data\\image\\rag_scheme_retrival.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47feb874",
   "metadata": {},
   "source": [
    "Этот модуль - сердце RAG. Отвечает за поиск релевантной информации на основе пользовательского запроса. По сути, он работает как умный поисковик: принимает текст запроса, преобразует его в вектор с помощью той же embedding-модели, и выполняет семантический поиск в базе данных QDrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6085d",
   "metadata": {},
   "source": [
    "Код ниже взят из документации [pyTorch v1.0.0](https://docs.pytorch.org/docs/1.0.0/notes/extending.html?highlight=staticmethod%20def%20forward%20ctx%20input%20weight%20bias%20none%20ctx%20save_for_backward%20input%20weight%20bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c41197",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_code = \"\"\"\n",
    "import torch\n",
    "from torch.autograd import gradcheck, Function\n",
    "\n",
    "class LinearFunction(Function):\n",
    "\n",
    "    \n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def backward(ctx, grad_output):\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output.mm(weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n",
    "\n",
    "input = (torch.randn(20,20,dtype=torch.double,requires_grad=True), torch.randn(30,20,dtype=torch.double,requires_grad=True))\n",
    "linear = LinearFunction.apply\n",
    "test = gradcheck(linear, input, eps=1e-6, atol=1e-4)\n",
    "print(test)\n",
    "\n",
    "\"\"\"\n",
    "documents = rtr._get_retriever_for_langChain(k=6).invoke(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e927b12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'version': 'v1.2.0', 'release_name': 'New TorchScript API with Improved Python Language Coverage, Expanded ONNX Export, NN.Transformer', 'chunk_id': 'v1.2.0-51', '_id': '3dbcc1bb-db5a-46d9-b2a2-253a4aacd2ea', '_collection_name': 'migTorch_test_intfloat_e5-large'}, page_content=\"is now deprecated, please use 'out' parameter with dtype torch.bool instead.\\r\\n\\r\\ntensor([0, 1, 1], dtype=torch.uint8)\\r\\n\\r\\n# instead use torch.bool\\r\\n>>> res = torch.empty_like(a, dtype=torch.bool)\\r\\n>>> torch.gt(a, b, out=res)\\r\\ntensor([False, True, True])\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n### Legacy `autograd.Function` (Function without static forward method) is now deprecated\\r\\n\\r\\n```\\r\\n>>> class MyLegacyFunction(Function):\\r\\n>>>     def forward(self, x):\\r\\n>>>         return x\\r\\n>>>\\r\\n>>>     def backward(self, grad_output):\\r\\n>>>         return grad_output\\r\\n>>>\\r\\n>>> MyLegacyFunction()(torch.randn((3,), requires_grad=True)\\r\\nUserWarning: Legacy autograd function with non-static forward method is deprecated\\r\\nand will be removed in 1.3. Please use new-style autograd function\\r\\nwith static forward method.\\r\\n\\r\\n# instead use new-style Autograd Function\\r\\n>>> class MyFunction(Function):\\r\\n>>>     @staticmethod\\r\\n>>>     def forward(ctx, x):\\r\\n>>>         return x\\r\\n>>>\\r\\n>>>     @staticmethod\\r\\n>>>     def backward(ctx, grad_output):\\r\\n>>>         return grad_output\\r\\n>>>\\r\\n>>> MyFunction.apply(torch.randn((3,), requires_grad=True)\\r\\n```\\r\\n\\r\\nSee the [torch.autograd.Function](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function) documentation for more details.\\r\\n\\r\\n### `torch.gels`: has been renamed to `torch.lstsq`; `torch.gels` will work for this release but is now deprecated.  ([23460](https://github.com/pytorch/pytorch/pull/23460))\\r\\n\\r\\n## Performance\"),\n",
       " Document(metadata={'version': 'v1.8.0', 'release_name': 'PyTorch 1.8 Release, including Compiler and Distributed Training updates, New Mobile Tutorials and more', 'chunk_id': 'v1.8.0-13', '_id': '1e0afe91-04ca-4227-ab10-3fc0dbf3bec7', '_collection_name': 'migTorch_test_intfloat_e5-large'}, page_content='An example of this discrepancy is shown in the example below where a Linear layer takes as input a single Tensor of size 5 and returns a single Tensor of size 5 but old style hook would return two gradients with respect to the input for only one input.\\r\\n\\r\\n1.7.1:\\r\\n\\r\\n```python\\r\\nimport torch\\r\\nfrom torch import nn\\r\\n\\r\\nmod = nn.Linear(5, 5)\\r\\ndef hook(mod, grad_inp, grad_out):\\r\\n    print(f\"grad input size: \" + \" \".join(str(g.size()) for g in grad_inp))\\r\\n    print(f\"grad output size: \" + \" \".join(str(g.size()) for g in grad_out))\\r\\nmod.register_backward_hook(hook)\\r\\n\\r\\nmod(torch.rand(5, requires_grad=True)).sum().backward()\\r\\n>>> `grad input size: torch.Size([5]) torch.Size([5]) # One too many\\r\\n>>> grad output size: torch.Size([5])`\\r\\n```\\r\\n\\r\\n1.8.0:\\r\\nOld style hooks are deprecated and will warn when providing wrong result.\\r\\n\\r\\n```python\\r\\nimport torch\\r\\nfrom torch import nn\\r\\n\\r\\nmod = nn.Linear(5, 5)\\r\\ndef hook(mod, grad_inp, grad_out):\\r\\n    print(f\"grad input size: \" + \" \".join(str(g.size()) for g in grad_inp))\\r\\n    print(f\"grad output size: \" + \" \".join(str(g.size()) for g in grad_out))\\r\\nmod.register_backward_hook(hook)\\r\\n\\r\\nmod(torch.rand(5, requires_grad=True)).sum().backward()\\r\\n>>> grad input size: torch.Size([5]) torch.Size([5]) # One too many\\r\\n>>> grad output size: torch.Size([5])\\r\\n>>> `UserWarning: Using a non-full backward hook when the forward contains multiple\\r\\nautograd Nodes is deprecated and will be removed in future versions. This hook\\r\\nwill be missing some grad_input.`\\r\\n```'),\n",
       " Document(metadata={'version': 'v1.13.0', 'release_name': 'PyTorch 1.13: beta versions of functorch and improved support for Apple’s new M1 chips are now available', 'chunk_id': 'v1.13.0-6', '_id': 'f45870ba-d440-4f53-a573-ee3c4cca3f23', '_collection_name': 'migTorch_test_intfloat_e5-large'}, page_content='Setting the  `.data` of a tensor that `requires_grad` with an integer tensor now raises an error.\\r\\n\\r\\n1.12.1\\r\\n\\r\\n```python\\r\\n>>> x = torch.randn(2, requires_grad=True)\\r\\n>>> x.data = torch.randint(1, (2,))\\r\\n>>> x\\r\\ntensor([0, 0], requires_grad=True)\\r\\n```\\r\\n\\r\\n1.13\\r\\n\\r\\n```python\\r\\n>>> x = torch.randn(2, requires_grad=True)\\r\\n>>> x.data = torch.randint(1, (2,))\\r\\nTraceback (most recent call last):\\r\\n  File \"<stdin>\", line 1, in <module>\\r\\nRuntimeError: data set to a tensor that requires gradients must be floating point or complex dtype\\r\\n```\\r\\n\\r\\n### Added variable_list support to ExtractVariables struct (#84583)\\r\\n\\r\\nPrior to this change, C++ custom autograd Function considers tensors passed in TensorList to not be tensors for the purposes of recording the backward graph. After this change, custom Functions that receive TensorList must modify their backward functions to also compute gradients for these additional tensor inputs. Note that this behavior now differs from that of custom autograd Functions in Python.\\r\\n\\r\\n1.12.1\\r\\n\\r\\n```cpp\\r\\nstruct MyFunction : public Function<MyFunction> {\\r\\n    static Variable forward(AutogradContext* ctx, at::Tensor t, at::TensorList tensors) {\\r\\n      return 2 * tensors[0] + 3 * t;\\r\\n    }\\r\\n\\r\\n    static variable_list backward(\\r\\n        AutogradContext* ctx,\\r\\n        variable_list grad_output) {\\r\\n      return {3 * grad_output[0]};\\r\\n    }\\r\\n};\\r\\n```\\r\\n\\r\\n1.13\\r\\n\\r\\n```cpp\\r\\nstruct MyFunction : public Function<MyFunction> {\\r\\n    static Variable forward(AutogradContext* ctx, at::Tensor t, at::TensorList tensors) {\\r\\n      return 2 * tensors[0] + 3 * t;\\r\\n    }\\r\\n\\r\\n    static variable_list backward(\\r\\n        AutogradContext* ctx,\\r\\n        variable_list grad_output) {\\r\\n      return {3 * grad_output[0], 2 * grad_output[0]};\\r\\n    }\\r\\n};\\r\\n```'),\n",
       " Document(metadata={'version': 'v1.7.0', 'release_name': 'PyTorch 1.7 released w/ CUDA 11, New APIs for FFTs, Windows support for Distributed training and more', 'chunk_id': 'v1.7.0-18', '_id': 'e2ff536c-4fa0-4e40-998c-ab56c7f877d9', '_collection_name': 'migTorch_test_intfloat_e5-large'}, page_content='>>> bceloss(a, b)\\r\\nValueError: Using a target size (torch.Size([25, 1]))\\r\\nthat is different to the input size (torch.Size([25]))\\r\\nis deprecated. Please ensure they have the same size.\\r\\n>>> b = b.reshape(25)\\r\\n>>> bceloss(a, b)\\r\\ntensor(1.0604)\\r\\n      </pre></sub></td>\\r\\n    </tr>\\r\\n  </table>\\r\\n</p>\\r\\n\\r\\n### Custom `autograd.Function` stop materializing `None` output Tensors ([#41490](https://github.com/pytorch/pytorch/pull/41490))\\r\\n\\r\\nTo improve performance, the custom `autograd.Function` will not create a Tensor full of zeros when an input is differentiable but the user’s `backward` function returns `None` for it. This means that code for which the `.backward()` or `autograd.grad()` final result will now be `None` while it used to be a Tensor full of zeros.\\r\\nYou can recover the previous behavior by having your custom `autograd.Function` materialize the zero Tensor with `torch.zeros_like(input)` to replace the `None` output for the `backward` method.\\r\\n\\r\\n```python\\r\\nimport torch\\r\\n\\r\\n# Custom Function that returns None for the gradient\\r\\nclass GetTwos(torch.autograd.Function):\\r\\n    @staticmethod\\r\\n    def forward(ctx, inp):\\r\\n        return inp.clone().fill_(2)\\r\\n\\r\\n    @staticmethod\\r\\n    def backward(ctx, grad_out):\\r\\n        # To recover the 1.6 behavior, replace the line below with `return torch.zeros_like(grad_out)`\\r\\n        return None\\r\\n\\r\\na = torch.rand(10, requires_grad=True)\\r\\nb = GetTwos.apply(a)\\r\\nb.sum().backward()\\r\\n\\r\\nprint(a.grad)\\r\\n# In PyTorch 1.6 this will print\\r\\n# tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\\r\\n# In PyTorch 1.7 this will print')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2d33f",
   "metadata": {},
   "source": [
    "Что выдал нам retrival?\n",
    "\n",
    "* v 1.2.0 - говорится, что стоит использовать ```@staticmethod``` перед методами нашей кастомной автоградиентной функцией.\n",
    "\n",
    "* v 1.5.0 - затрагивается ```output = input.mm(weight.t())``` из ```LinearFunction.forward()```  говорится, что лучше клонировать наш вход и работать с клонами. В нашем случае мы именно так и делаем.\n",
    "\n",
    "* v 1.7.0 - изменение поведения градиента ctx.needs_input_grad выводил None, теперь выводит zero.\n",
    "\n",
    "* v 1.13.0 - информация о низкоуровневых изменениях вычисления градиента\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e52ef2",
   "metadata": {},
   "source": [
    "Конеченый этап"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799fc47",
   "metadata": {},
   "source": [
    "![Retrieval](data\\image\\rag_scheme_response.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c3a58",
   "metadata": {},
   "source": [
    "Тут остаётся самое лёгкое, формируется запрос путём подставления изначально запроса и релевантного контекста, о котором нам говорит наш ретривал."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec8fe33",
   "metadata": {},
   "source": [
    "Вот так выглядит наш промт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You are a senior PyTorch engineer helping migrate code from v1.0 to v2.7.\n",
    "\n",
    "### Original code (v1.0)\n",
    "```python\n",
    "{old_code}\n",
    "```\n",
    "\n",
    "### Context (docs & changelog)\n",
    "{context}\n",
    "\n",
    "### Task\n",
    "Rewrite the code so it runs on **PyTorch 2.7**. Explain what you changed.\n",
    "\n",
    "### Answer format\n",
    "First, provide the updated code in the following format:\n",
    "```python\n",
    "import torch\n",
    "# updated code here\n",
    "```\n",
    "Then, after the code block, provide a detailed explanation as a single continuous paragraph of text describing the changes you made and the reasons for each change.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f2ea6",
   "metadata": {},
   "source": [
    "## Практика и метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa66708",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459afa2",
   "metadata": {},
   "source": [
    "Метрики при наличии 21 теста с вариантами, когда есть рабочий и не рабочий код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1e9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830091d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is work in 1.0.0</th>\n",
       "      <th>Is work in 1.0.0 (%)</th>\n",
       "      <th>Is work in 2.7.0</th>\n",
       "      <th>Is work in 2.7.0 (%)</th>\n",
       "      <th>Is work in 2.7.0 (RAG)</th>\n",
       "      <th>Is work in 2.7.0 (RAG) (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BAAI_bge-base-en.csv</th>\n",
       "      <td>10</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>6</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>14</td>\n",
       "      <td>73.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAAI_bge-large-en.csv</th>\n",
       "      <td>10</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>6</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>15</td>\n",
       "      <td>78.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat_e5-large.csv</th>\n",
       "      <td>10</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>6</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>16</td>\n",
       "      <td>84.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers_all-MiniLM-L6-v2.csv</th>\n",
       "      <td>10</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>6</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>17</td>\n",
       "      <td>89.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers_LaBSE.csv</th>\n",
       "      <td>10</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>6</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>16</td>\n",
       "      <td>84.210526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Is work in 1.0.0  \\\n",
       "BAAI_bge-base-en.csv                                      10   \n",
       "BAAI_bge-large-en.csv                                     10   \n",
       "intfloat_e5-large.csv                                     10   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                10   \n",
       "sentence-transformers_LaBSE.csv                           10   \n",
       "\n",
       "                                            Is work in 1.0.0 (%)  \\\n",
       "BAAI_bge-base-en.csv                                   52.631579   \n",
       "BAAI_bge-large-en.csv                                  52.631579   \n",
       "intfloat_e5-large.csv                                  52.631579   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv             52.631579   \n",
       "sentence-transformers_LaBSE.csv                        52.631579   \n",
       "\n",
       "                                            Is work in 2.7.0  \\\n",
       "BAAI_bge-base-en.csv                                       6   \n",
       "BAAI_bge-large-en.csv                                      6   \n",
       "intfloat_e5-large.csv                                      6   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                 6   \n",
       "sentence-transformers_LaBSE.csv                            6   \n",
       "\n",
       "                                            Is work in 2.7.0 (%)  \\\n",
       "BAAI_bge-base-en.csv                                   31.578947   \n",
       "BAAI_bge-large-en.csv                                  31.578947   \n",
       "intfloat_e5-large.csv                                  31.578947   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv             31.578947   \n",
       "sentence-transformers_LaBSE.csv                        31.578947   \n",
       "\n",
       "                                            Is work in 2.7.0 (RAG)  \\\n",
       "BAAI_bge-base-en.csv                                            14   \n",
       "BAAI_bge-large-en.csv                                           15   \n",
       "intfloat_e5-large.csv                                           16   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                      17   \n",
       "sentence-transformers_LaBSE.csv                                 16   \n",
       "\n",
       "                                            Is work in 2.7.0 (RAG) (%)  \n",
       "BAAI_bge-base-en.csv                                         73.684211  \n",
       "BAAI_bge-large-en.csv                                        78.947368  \n",
       "intfloat_e5-large.csv                                        84.210526  \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                   89.473684  \n",
       "sentence-transformers_LaBSE.csv                              84.210526  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def analyz_test():\n",
    "    csv_files = glob.glob(\"*.csv\", root_dir=\"data/\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        dfTest = pd.read_csv(\"data/\"+csv_file)\n",
    "        сount_test = len(dfTest)\n",
    "\n",
    "        count_works_1_0 = dfTest['Is work in 1.0.0'].sum()\n",
    "        count_works_2_7 = dfTest['Is work in 2.7.0'].sum()\n",
    "        count_rag_2_7 = dfTest['Is work in 2.7.0 (после RAG)'].sum()\n",
    "\n",
    "        pct_works_1_0 = (count_works_1_0 / сount_test) * 100\n",
    "        pct_works_2_7 = (count_works_2_7 / сount_test) * 100\n",
    "        pct_rag_2_7 = (count_rag_2_7 / сount_test) * 100\n",
    "\n",
    "        result_dict = {\n",
    "            \"Is work in 1.0.0\": count_works_1_0,\n",
    "            \"Is work in 1.0.0 (%)\": pct_works_1_0,\n",
    "            \"Is work in 2.7.0\": count_works_2_7,\n",
    "            \"Is work in 2.7.0 (%)\": pct_works_2_7,\n",
    "            \"Is work in 2.7.0 (RAG)\": count_rag_2_7,\n",
    "            \"Is work in 2.7.0 (RAG) (%)\": pct_rag_2_7,\n",
    "        }\n",
    "\n",
    "        results.append(result_dict)\n",
    "    \n",
    "    return pd.DataFrame(results, index=csv_files)\n",
    "\n",
    "analyz_test()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2ddc883b",
   "metadata": {},
   "source": [
    "![метрики](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed01b7",
   "metadata": {},
   "source": [
    "Метрика при наличии 9 тестов, которые работают в v1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125a29aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is work in 1.0.0</th>\n",
       "      <th>Is work in 1.0.0 (%)</th>\n",
       "      <th>Is work in 2.7.0</th>\n",
       "      <th>Is work in 2.7.0 (%)</th>\n",
       "      <th>Is work in 2.7.0 (RAG)</th>\n",
       "      <th>Is work in 2.7.0 (RAG) (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BAAI_bge-base-en.csv</th>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>8</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAAI_bge-large-en.csv</th>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>8</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat_e5-large.csv</th>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>7</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers_all-MiniLM-L6-v2.csv</th>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>8</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers_LaBSE.csv</th>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>8</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Is work in 1.0.0  \\\n",
       "BAAI_bge-base-en.csv                                       9   \n",
       "BAAI_bge-large-en.csv                                      9   \n",
       "intfloat_e5-large.csv                                      9   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                 9   \n",
       "sentence-transformers_LaBSE.csv                            9   \n",
       "\n",
       "                                            Is work in 1.0.0 (%)  \\\n",
       "BAAI_bge-base-en.csv                                       100.0   \n",
       "BAAI_bge-large-en.csv                                      100.0   \n",
       "intfloat_e5-large.csv                                      100.0   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                 100.0   \n",
       "sentence-transformers_LaBSE.csv                            100.0   \n",
       "\n",
       "                                            Is work in 2.7.0  \\\n",
       "BAAI_bge-base-en.csv                                       1   \n",
       "BAAI_bge-large-en.csv                                      1   \n",
       "intfloat_e5-large.csv                                      1   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                 1   \n",
       "sentence-transformers_LaBSE.csv                            1   \n",
       "\n",
       "                                            Is work in 2.7.0 (%)  \\\n",
       "BAAI_bge-base-en.csv                                   11.111111   \n",
       "BAAI_bge-large-en.csv                                  11.111111   \n",
       "intfloat_e5-large.csv                                  11.111111   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv             11.111111   \n",
       "sentence-transformers_LaBSE.csv                        11.111111   \n",
       "\n",
       "                                            Is work in 2.7.0 (RAG)  \\\n",
       "BAAI_bge-base-en.csv                                             8   \n",
       "BAAI_bge-large-en.csv                                            8   \n",
       "intfloat_e5-large.csv                                            7   \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                       8   \n",
       "sentence-transformers_LaBSE.csv                                  8   \n",
       "\n",
       "                                            Is work in 2.7.0 (RAG) (%)  \n",
       "BAAI_bge-base-en.csv                                         88.888889  \n",
       "BAAI_bge-large-en.csv                                        88.888889  \n",
       "intfloat_e5-large.csv                                        77.777778  \n",
       "sentence-transformers_all-MiniLM-L6-v2.csv                   88.888889  \n",
       "sentence-transformers_LaBSE.csv                              88.888889  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def analyz_test():\n",
    "    csv_files = glob.glob(\"*.csv\", root_dir=\"data/\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        dfTest = pd.read_csv(\"data/\"+csv_file)\n",
    "        сount_test = len(dfTest)\n",
    "\n",
    "        count_works_1_0 = dfTest['Is work in 1.0.0'].sum()\n",
    "        count_works_2_7 = dfTest['Is work in 2.7.0'].sum()\n",
    "        count_rag_2_7 = dfTest['Is work in 2.7.0 (после RAG)'].sum()\n",
    "\n",
    "        pct_works_1_0 = (count_works_1_0 / сount_test) * 100\n",
    "        pct_works_2_7 = (count_works_2_7 / сount_test) * 100\n",
    "        pct_rag_2_7 = (count_rag_2_7 / сount_test) * 100\n",
    "\n",
    "        result_dict = {\n",
    "            \"Is work in 1.0.0\": count_works_1_0,\n",
    "            \"Is work in 1.0.0 (%)\": pct_works_1_0,\n",
    "            \"Is work in 2.7.0\": count_works_2_7,\n",
    "            \"Is work in 2.7.0 (%)\": pct_works_2_7,\n",
    "            \"Is work in 2.7.0 (RAG)\": count_rag_2_7,\n",
    "            \"Is work in 2.7.0 (RAG) (%)\": pct_rag_2_7,\n",
    "        }\n",
    "\n",
    "        results.append(result_dict)\n",
    "    \n",
    "    return pd.DataFrame(results, index=csv_files)\n",
    "\n",
    "analyz_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "migratetorch_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
